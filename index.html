<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">

    <meta property='og:title' content='Localizing Knowledge in Diffusion Transformers'/>
    <meta property='og:url' content='https://github.com/ArmanZarei/Localizing-Knowledge-in-DiTs'/>
    <meta property="og:image" content="static/images/banner.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <title>Localizing Knowledge in Diffusion Transformers</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
    rel="stylesheet">
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/tab_gallery.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.svg">
    <link rel="stylesheet" href="juxtapose/css/juxtapose.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
    <script src="./static/js/magnifier.js"></script>
    <link href="https://fonts.cdnfonts.com/css/menlo" rel="stylesheet">
    <link rel="stylesheet" href="./static/css/image_card_fader.css">
    <link rel="stylesheet" href="./static/css/image_card_slider.css">

</head>

<body>
  <section class="hero banner">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Localizing Knowledge in Diffusion Transformers</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://armanzarei.github.io/">Arman Zarei</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://samyadeepbasu.github.io">Samyadeep Basu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://k1rezaei.github.io/">Keivan Rezaei</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=4h_A4n4AAAAJ&hl=en">Zihao Lin</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=K8w4dj4AAAAJ&hl=en">Sayan Nag</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.cs.umd.edu/~sfeizi/">Soheil Feizi</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <sup>1</sup><span class="author-block" style="margin-right: 25px;">University of Maryland</span> <sup>2</sup><span class="author-block" style="margin-right: 25px;">University of California, Davis</span> <sup>3</sup><span class="author-block">Adobe</span>
          </div>

          <div class="is-size-5 publication-venue">
            NeurIPS 2025
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2505.18832"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2505.18832"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ArmanZarei/DiT-Knowledge-Localization"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/ArmanZarei/DiT-Knowledge-Localization"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fa fa-database"></i>
                  </span>
                  <span>Dataset</span>
                  </a>
              </span>
              <span class="link-block">
                <a href="#bibtex"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-obp"></i>
                  </span>
                  <span>BibTex</span>
                </a>
              </span> 
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>






<section class="section">

  <div class="container is-max-desktop">
    <!-- Abstract. -->
  <div class="content has-text-centered">
    <img src="./static/images/localization_layer_freq2.jpg" width="100%">
    <p style="text-align: justify;"><b>Localization across various DiT models and knowledge categories.</b> For each model, heatmaps indicate the frequency of each block being selected as a dominant carrier of different target knowledge. <span style="color: #27ae60">Green</span>-bordered images are standard generations, while <span style="color: #C0392B">red</span>-bordered images result from withholding knowledge-specific information in the localized blocks. Our method successfully localizes diverse knowledge types, with variation in localization patterns across models.</p>
  </div>
    <div class="columns is-centered has-text-centered" style="margin-top: 50px;">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Understanding how knowledge is distributed across the layers of generative models is crucial for improving interpretability, controllability, and adaptation. While prior work has explored knowledge localization in UNet-based architectures, Diffusion Transformer (DiT)-based models remain underexplored in this context. In this paper, we propose a model- and knowledge-agnostic method to localize where specific types of knowledge are encoded within the DiT blocks. We evaluate our method on state-of-the-art DiT-based models, including PixArt-alpha, FLUX, and SANA, across six diverse knowledge categories. We show that the identified blocks are both interpretable and causally linked to the expression of knowledge in generated outputs.
Building on these insights, we apply our localization framework to two key applications: <i>model personalization</i> and <i>knowledge unlearning</i>. In both settings, our localized fine-tuning approach enables efficient and targeted updates, reducing computational cost, improving task-specific performance, and better preserving general model behavior with minimal interference to unrelated or surrounding content.
Overall, our findings offer new insights into the internal structure of DiTs and introduce a practical pathway for more interpretable, efficient, and controllable model editing.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<section class="section">
  
    <!--/ Matting. -->
    <div class="container is-max-desktop">
    
    <!-- Latent space editing applications -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Method</h2>

        <div class="content has-text-centered">
          <img src="./static/images/localization.jpg" width="90%">
        </div>

        <!-- Prompt Interpolation image -->
        
        
        <div class="content has-text-justified">
          <p>
            <!-- We first generate images from prompts \(\{p_i^\kappa\}\) containing target knowledge \(\kappa\), and compute token-level attention contributions across layers. Aggregated scores identify the top-\(K\) blocks \(\mathcal{B}_K^\kappa\) most responsible for encoding \(\kappa\). Replacing their inputs with knowledge-agnostic prompts \(\{p_i^{\kappa\text{-neutral}}\}\) suppresses the knowledge in the output. -->

            Given a target knowledge $\kappa$, we first construct a set of prompts $\{p_1^\kappa, p_2^\kappa, \dots, p_N^\kappa\}$ that contain the knowledge, either manually or using an LLM. Using the DiT model, we generate images and compute the attention contribution of the tokens $\{\mathbf{x}_{j_1}, \mathbf{x}_{j_2}, \dots, \mathbf{x}_{j_\tau}\}$ corresponding to $\kappa$ in each prompt $p_i^\kappa$ at each layer (step 1 in the figure). These values are averaged across seeds and prompts to obtain a per-layer score indicating how much each block contributes to injecting the knowledge into the image (step 2 in the figure). We then select the top-$K$ most dominant blocks ($\mathcal{B}_K^\kappa$) as the most informative.

To verify the role of the localized blocks $\mathcal{B}_K^\kappa$, we generate images using the original prompts $\{p_1^\kappa, p_2^\kappa, \dots, p_N^\kappa\}$, but replace the inputs to the $\mathcal{B}_K^\kappa$ with knowledge-agnostic prompts $\{p_1^{\kappa\text{-neutral}}, p_2^{\kappa\text{-neutral}}, \dots, p_N^{\kappa\text{-neutral}}\}$, which omit the knowledge (step 3 in the figure). In models like PixArt-$\alpha$, this is done by swapping the cross-attention input, and for MMDiT-based models like FLUX, which use a separate prompt branch, we perform two passes, one with $\{p_i^\kappa\}$ and one with $\{p_i^{\kappa\text{-neutral}}\}$, and overwrite the text branch input in the $\mathcal{B}_K^\kappa$ of the first pass with those from the second.
          </p>
          <br>
        </div>
        <!-- Prompt Interpolation image -->
        <h3 class="title is-4 has-text-centered">Results</h3>
        <br>
        
        <div class="content has-text-centered">
          <img src="./static/images/localization_radar_and_qualitative.jpg" width="90%">
          <p style="text-align: justify;"><b>Differences in how knowledge is localized across categories and models.</b> LLaVA-based evaluations and generation samples as the number of intervened blocks $K$ increases, where $K$ denotes the top-$K$ most informative blocks identified by our localization method. Some knowledge types (e.g., copyright) are highly concentrated in a few blocks, while others (e.g., animals) are more distributed across the model. Examples include outputs from the base models and their intervened counterparts.</p>
        </div>
        <br>

        <div class="container is-max-desktop has-text-centered">
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item item-t2i1">
              <img id="myt2i0" src="./static/images/results_slider_localization/Slide1.JPG"
              class="interpolation-image"/>
            </div>
            <div class="item item-t2i1">
              <img id="myt2i0" src="./static/images/results_slider_localization/Slide2.JPG"
              class="interpolation-image"/>
            </div>
            <div class="item item-t2i1">
              <img id="myt2i0" src="./static/images/results_slider_localization/Slide3.JPG"
              class="interpolation-image"/>
            </div>
            <div class="item item-t2i1">
              <img id="myt2i0" src="./static/images/results_slider_localization/Slide4.JPG"
              class="interpolation-image"/>
            </div>
            <div class="item item-t2i1">
              <img id="myt2i0" src="./static/images/results_slider_localization/Slide5.JPG"
              class="interpolation-image"/>
            </div>
            <div class="item item-t2i1">
              <img id="myt2i0" src="./static/images/results_slider_localization/Slide6.JPG"
              class="interpolation-image"/>
            </div>
            <div class="item item-t2i1">
              <img id="myt2i0" src="./static/images/results_slider_localization/Slide7.JPG"
              class="interpolation-image"/>
            </div>
            <div class="item item-t2i1">
              <img id="myt2i0" src="./static/images/results_slider_localization/Slide8.JPG"
              class="interpolation-image"/>
            </div>
          </div>
          <p>Qualitative examples of knowledge localization in FLUX across different values of $K$</p>
        </div>
        <br><br>

        
        <div class="content has-text-centered">
          <img src="./static/images/style_and_k.jpg" width="90%">
          <p style="text-align: justify;"><b>Variation in how artistic styles are localized within the model.</b> We report CSD scores for various artists in the PixArt-$\alpha$ model as the number of intervened blocks $K$ increases. The numbers indicate how many artist styles remain identifiable at each $K$. While styles like <i>Patrick Caulfield</i> are localized in fewer blocks, others like <i>Van Gogh</i> are distributed more.</p>
        </div>
        <br><br>

        <div class="content has-text-centered">
          <img src="./static/images/simplicity_style_localization.jpg" width="80%">
          <p style="text-align: justify;"><b>Relationship between artistic style complexity and the number of blocks required for localization.</b> For each artist, we identify the minimum number of blocks $K$ needed to localize their style. Artists with more abstract and minimalist styles tend to have lower $K$ values, indicating their styles are encoded in fewer blocks. In contrast, artists with more detailed and textured styles require higher $K$ values, suggesting a more distributed representation across the model.</p>
        </div>
        <br>

      </div>
    </div>


    <!-- Latent space editing applications -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Applications</h2>
        
        <div class="content has-text-centered">
            <img src="./static/images/applications.jpg" width="90%">
            <p style="text-align: justify;"><b>Targeted fine-tuning via knowledge localization.</b> Given a concept to personalize or remove, our method first identifies the most relevant blocks via knowledge localization and restricts fine-tuning to those blocks. This enables efficient adaptation (top) and targeted suppression (bottom) with minimal impact on surrounding content, while better preserving the modelâ€™s prior performance.</p>
        </div>
        <br>
        
        <h3 class="title is-4 has-text-centered">Results</h3>
        <br>

        <div class="content has-text-centered">
            <img src="./static/images/dreambooth_qualitative.jpg" width="90%">
            <p style="text-align: justify;"><b>Improved prompt alignment and surrounding identity preservation via localized DreamBooth.</b> Left: Localized fine-tuning better adheres to prompt specifications. Right: Surrounding class-level identities are better preserved, demonstrating reduced interference with other concepts.</p>
        </div>
        <br>

        <div class="content has-text-centered">
            <img src="./static/images/unlearning_qualitative.jpg" width="90%">
            <p style="text-align: justify;"><b>Quantitative results showing comparable performance with localized unlearning while being more efficient.</b> Localized unlearning achieves comparable target erasure while better preserving surrounding identities, anchor alignment, and overall generation quality (FID), compared to full-model fine-tuning.</p>
        </div>

      </div>
    </div>
  </div>

  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title"><a id="bibtex">BibTeX</a></h2>
    <pre><code>@article{zarei2025localizing,
  title={Localizing Knowledge in Diffusion Transformers},
  author={Zarei, Arman and Basu, Samyadeep and Rezaei, Keivan and Lin, Zihao and Nag, Sayan and Feizi, Soheil},
  journal={arXiv preprint arXiv:2505.18832},
  year={2025}
}</code></pre>
  </div>
</section>



<footer class="footer">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website adapted from the following <a href="https://github.com/nerfies/nerfies.github.io">source code</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


<script src="juxtapose/js/juxtapose.js"></script>

<script>
var slider;
let origImages = [
  {"src": "./static/images/corgi_input.jpeg", "label": "Generated by SDXL-Diffusion2GAN (512px)",},
  {"src": "./static/images/corgi_output.jpeg", "label": "8 x Upsampled by GigaGAN (4K)",}
];
let origOptions = {
    "makeResponsive": true,
    "showLabels": true,
    "mode": "horizontal",
    "showCredits": true,
    "animate": true,
    "startingPosition": "50"
};

const juxtaposeSelector = "#juxtapose-embed";
const transientSelector = "#juxtapose-hidden";


function tab_gallery_click(name) {
  // Get the expanded image
  let inputImage = {
    label: "Generated by Diffusion2GAN (512px)",
  };
  let outputImage = {
    label: "8 x Upsampled by GigaGAN (4K)",
  };

  inputImage.src = "./static/images/".concat(name, "_input.jpeg")
  outputImage.src = "./static/images/".concat(name, "_output.jpeg")

  let images = [inputImage, outputImage];
  let options = slider.options;
  options.callback = function(obj) {
      var newNode = document.getElementById(obj.selector.substring(1));
      var oldNode = document.getElementById(juxtaposeSelector.substring(1));
      console.log(obj.selector.substring(1));
      console.log(newNode.children[0]);
      oldNode.replaceChild(newNode.children[0], oldNode.children[0]);
      //newNode.removeChild(newNode.children[0]);
      
  };
  
  slider = new juxtapose.JXSlider(transientSelector, images, options);
};



(function() {
    slider = new juxtapose.JXSlider(
        juxtaposeSelector, origImages, origOptions);
    //document.getElementById("left-button").onclick = replaceLeft;
    //document.getElementById("right-button").onclick = replaceRight;
})();
  // Get the image text
  var imgText = document.getElementById("imgtext");
  // Use the same src in the expanded image as the image being clicked on from the grid
  // expandImg.src = imgs.src;
  // Use the value of the alt attribute of the clickable image as text inside the expanded image
  imgText.innerHTML = name;
  // Show the container element (hidden with CSS)
  // expandImg.parentElement.style.display = "block";

$(".flip-card").click(function() {
            console.log("fading in")
            div_back = $(this).children().children()[1]
            div_front = $(this).children().children()[0]
            // console.log($(this).children("div.flip-card-back"))
            console.log(div_back)
            $(div_front).addClass("out");
            $(div_front).removeClass("in");

            $(div_back).addClass("in");
            $(div_back).removeClass("out");

});

$(".flip-card").mouseleave(function() {
            console.log("fading in")
            div_back = $(this).children().children()[1]
            div_front = $(this).children().children()[0]
            // console.log($(this).children("div.flip-card-back"))
            console.log(div_back)
            $(div_front).addClass("in");
            $(div_front).removeClass("out");

            $(div_back).addClass("out");
            $(div_back).removeClass("in");

});

</script>
<!-- <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js" type="text/javascript"></script> -->
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/js/bootstrap.min.js"></script>    

<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  }
};
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</body>
</html>
